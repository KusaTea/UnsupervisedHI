{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "from himodule.custom_classes import NasaDataset, SimpleAE, LossAndMetric\n",
    "from himodule.ae_metrics import MAPE\n",
    "from himodule.normalisation import StandardScaler, MinMaxScaler\n",
    "from himodule.secondary_funcs import save_object, check_path, split_dataset, seed_everything\n",
    "\n",
    "import os\n",
    "\n",
    "sns.set_theme(style='whitegrid', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 37\n",
    "\n",
    "# Whole dataset loading\n",
    "train_dataset = NasaDataset('../datasets/clean_train_data.csv')\n",
    "seed_everything(seed)\n",
    "# Get datasets for training and validation\n",
    "train_dataset, val_dataset = split_dataset(train_dataset, test_size=0.3)\n",
    "\n",
    "# Test dataset loading\n",
    "test_dataset = NasaDataset('../datasets/clean_test_data.csv')\n",
    "\n",
    "scaler = None\n",
    "try:\n",
    "    norm_name = repr(scaler).split(' ', maxsplit=2)[0].split('.')[-1]\n",
    "except IndexError:\n",
    "    norm_name = 'no_scaling'\n",
    "for idx, dtset in enumerate((train_dataset, val_dataset, test_dataset)):\n",
    "    dtset.to(device)\n",
    "    if scaler:\n",
    "        if idx == 0:\n",
    "            scaler.fit(dtset.dataset)\n",
    "        dtset.dataset = scaler.transform(dtset.dataset)\n",
    "\n",
    "# Save trained scaler to use it in another files    \n",
    "scaler_path = os.path.join('../scalers/', f'{norm_name}.pkl')\n",
    "if scaler and not os.path.exists(scaler_path):\n",
    "    save_object(scaler, scaler_path)\n",
    "\n",
    "seed_everything(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, worker_init_fn=seed, generator=g)\n",
    "seed_everything(seed)\n",
    "val_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, worker_init_fn=seed, generator=g)\n",
    "\n",
    "seed_everything(seed)\n",
    "test_loader = DataLoader(val_dataset, batch_size=20, shuffle=True, worker_init_fn=seed, generator=g)\n",
    "\n",
    "print(f'Train: {len(train_dataset)}\\nValidation: {len(val_dataset)}\\nTest: {len(test_dataset)}')\n",
    "\n",
    "input_shape = train_dataset.get_input_shape()\n",
    "layers_sizes = (8, 4, 2)\n",
    "\n",
    "# Model creating\n",
    "seed_everything(seed)\n",
    "model_ae = SimpleAE(input_shape, layers_sizes).to(device)\n",
    "loss_func = nn.MSELoss()\n",
    "metric_func = MAPE()\n",
    "get_loss_and_metric = LossAndMetric(loss_func, metric_func, scaler)\n",
    "optimiser = optim.AdamW(model_ae.parameters(),\n",
    "                       lr=1e-3)\n",
    "optimiser_name = repr(optimiser).split(' ', maxsplit=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module, loader: DataLoader, ):\n",
    "\n",
    "    '''Returns losses and metrics of trained model.'''\n",
    "\n",
    "    with torch.no_grad():\n",
    "        losses = list()\n",
    "        metrics = list()\n",
    "        for dta in loader:\n",
    "            sample = dta['sensors']\n",
    "            sample = sample.to(device)\n",
    "            _, reconstruction = model(sample)\n",
    "\n",
    "            loss, metric = get_loss_and_metric(reconstruction, sample)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            metrics.append(metric.item())\n",
    "    return losses, metrics\n",
    "\n",
    "\n",
    "def plot_history(loss_history_df: pd.DataFrame, metric_history_df: pd.DataFrame,\n",
    "                 test_losses: float, test_metrics: float,\n",
    "                 ylabel_loss: str = None, ylabel_metric: str = None, save_path: str = None):\n",
    "    \n",
    "    '''Makes plot with 4 axes: training losses and metrics, test losses, validation losses and metrics, test metrics.'''\n",
    "\n",
    "    loss_history_df = loss_history_df.melt(ignore_index=False).iloc[1:]\n",
    "    metric_history_df = metric_history_df.melt(ignore_index=False).iloc[1:]\n",
    "    fig = plt.figure(layout=\"constrained\")\n",
    "    fig.set_size_inches(10, 10)\n",
    "\n",
    "    gs = GridSpec(2, 5, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0:4])\n",
    "    ax2 = fig.add_subplot(gs[0, 4])\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[1, 0:4])\n",
    "    ax4 = fig.add_subplot(gs[1, 4])\n",
    "\n",
    "    sns.lineplot(data=loss_history_df,\n",
    "                x=loss_history_df.index,\n",
    "                y='value',\n",
    "                hue='variable',\n",
    "                ax=ax1)\n",
    "    ax1.set_ylabel(ylabel_loss)\n",
    "\n",
    "    sns.boxplot(x=['test_loss']*len(test_losses),\n",
    "                y=test_losses,\n",
    "                color='g',\n",
    "                ax=ax2)\n",
    "    ax2.set_ylabel(None)\n",
    "\n",
    "    sns.lineplot(data=metric_history_df,\n",
    "                x=metric_history_df.index,\n",
    "                y='value',\n",
    "                hue='variable',\n",
    "                ax=ax3)\n",
    "    ax3.set_ylabel(ylabel_metric)\n",
    "\n",
    "    ax3.set_ylim(0, 20)\n",
    "\n",
    "    sns.boxplot(x=['test_metric']*len(test_metrics),\n",
    "                y=test_metrics,\n",
    "                color='g',\n",
    "                ax=ax4)\n",
    "    ax4.set_ylabel(None)\n",
    "\n",
    "    ax4.set_ylim(0, 100)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "history = list()\n",
    "\n",
    "# Model training on normal and anomaly data\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = list()\n",
    "    train_metrics = list()\n",
    "    for dta in train_loader:\n",
    "        sample = dta['sensors']\n",
    "        sample = sample.to(device)\n",
    "        _, reconstruction = model_ae(sample)\n",
    "\n",
    "        loss, metric = get_loss_and_metric(reconstruction, sample)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_metrics.append(metric.item())\n",
    "    \n",
    "    val_losses, val_metrics = evaluate_model(model_ae, val_loader)\n",
    "    \n",
    "    train_loss, val_loss = mean(train_losses), mean(val_losses)\n",
    "    train_metrics, val_metrics = mean(train_metrics), mean(val_metrics)\n",
    "    history.append((epoch, train_loss, val_loss, train_metrics, val_metrics))\n",
    "    if (epoch + 1) % 10 == 0 or epoch == epochs - 1:\n",
    "        print(f'{epoch+1:>3}/{epochs:>3}: {train_loss=:.4f}, {val_loss=:.4f}, {train_metrics=:.4f}%, {val_metrics=:.4f}%')\n",
    "\n",
    "test_losses, test_metrics = evaluate_model(model_ae, test_loader)\n",
    "test_loss = mean(test_losses)\n",
    "test_metric = mean(test_metrics)\n",
    "print(f'\\n{test_loss=:.4f}, {test_metric=:.4f}%')\n",
    "\n",
    "\n",
    "# -------------------------------------------------- #\n",
    "name = str(layers_sizes)\n",
    "models_path = '../Models/'\n",
    "plot_path = '../Plots/history/'\n",
    "\n",
    "\n",
    "if True:\n",
    "    # Save model\n",
    "    pth = os.path.join(models_path, optimiser_name, norm_name)\n",
    "    check_path(pth)\n",
    "    torch.save(model_ae.state_dict(), os.path.join(pth, f'{name}.pth'))\n",
    "\n",
    "if True:\n",
    "    # Make plots to evaluate model performance\n",
    "\n",
    "    columns = ('epoch', 'train_loss', 'val_loss', 'train_metric', 'val_metric')\n",
    "    total_history_df = pd.DataFrame(history, columns=columns).set_index('epoch')\n",
    "\n",
    "    pth = os.path.join(plot_path, optimiser_name, norm_name)\n",
    "    check_path(pth)\n",
    "\n",
    "    loss_history_df = total_history_df.loc[:,('train_loss', 'val_loss')]\n",
    "    metric_history_df = total_history_df.loc[:,('train_metric', 'val_metric')]\n",
    "    plot_history(loss_history_df, metric_history_df, test_losses, test_metrics,\n",
    "                ylabel_loss='MSE', ylabel_metric='MAPE', save_path=os.path.join(pth, f'{name}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
