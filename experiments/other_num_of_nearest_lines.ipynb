{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='whitegrid', font_scale=1.2)\n",
    "\n",
    "from himodule.custom_classes import NasaDataset\n",
    "from himodule.linear_regression import LinearRegression\n",
    "from himodule.secondary_funcs import load_object, seed_everything, check_path\n",
    "from himodule.normalisation import MinMaxScaler\n",
    "from himodule.rul_metrics import RULScore, RMSELoss\n",
    "\n",
    "def find_closest_subarray(large_vector, small_vector):\n",
    "    large_len = len(large_vector)\n",
    "    small_len = len(small_vector)\n",
    "\n",
    "    min_diff = [float('inf')]*3\n",
    "    start_index = [0]*3\n",
    "\n",
    "    for i in range(large_len - small_len + 1):\n",
    "        subarray = large_vector[i:i + small_len]\n",
    "        diff = torch.sqrt(torch.sum(torch.square(subarray - small_vector))).item()\n",
    "\n",
    "        for idx, mdif in enumerate(min_diff):\n",
    "            if diff < mdif:\n",
    "                min_diff[idx] = diff\n",
    "                start_index[idx] = i\n",
    "\n",
    "    end_index = [st_index + small_len for st_index in start_index]\n",
    "    return start_index, end_index, min_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 37\n",
    "BATCH_SIZE = 20\n",
    "TRUE_HI_PATH = '../../Smoothed/train/'\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = NasaDataset('../../datasets/clean_train_data.csv')\n",
    "\n",
    "test_dataset = NasaDataset('../../datasets/clean_test_data.csv')\n",
    "\n",
    "scaler_path = '../../scalers/MinMaxScaler.pkl'\n",
    "scaler = load_object(scaler_path)\n",
    "\n",
    "for dataset in (train_dataset, test_dataset):\n",
    "    dataset.to(device)\n",
    "    dataset.dataset = scaler.transform(dataset.dataset)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "seed_everything(SEED)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, generator=g)\n",
    "\n",
    "seed_everything(SEED)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, generator=g)\n",
    "\n",
    "print(f'Train: {len(train_dataset)}, Test: {len(test_dataset)}')\n",
    "\n",
    "input_shape = test_dataset.get_input_shape()\n",
    "\n",
    "model_path = '../../LinearRegression/regression.pth'\n",
    "linear_model = LinearRegression(input_shape)\n",
    "linear_model.load_state_dict(torch.load(model_path))\n",
    "linear_model = linear_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(loader: DataLoader, dataset: NasaDataset, linear_model: LinearRegression):\n",
    "    predictions = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for dta in loader:\n",
    "            sample = dta['sensors']\n",
    "            sample = sample.to(device)\n",
    "            hi = linear_model(sample)\n",
    "\n",
    "            predictions.append(hi)\n",
    "\n",
    "    predictions = torch.vstack(predictions)\n",
    "    predictions = torch.concat((dataset.machine_ids[:, None], predictions), dim=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = get_predictions(test_loader, test_dataset, linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_RUL = dict()\n",
    "\n",
    "for machine_id in tqdm(test_dataset.machine_ids.unique(), file=sys.stdout):\n",
    "    machine_id = int(machine_id.item())\n",
    "    pred_vector = test_predictions[test_predictions[:,0] == machine_id][:,1].flatten()\n",
    "\n",
    "    storage = list()\n",
    "\n",
    "    for true_pth in glob.glob(os.path.join(TRUE_HI_PATH, '*.dat')):\n",
    "        true_vector = torch.FloatTensor(np.fromfile(true_pth)).to(device)\n",
    "\n",
    "        if len(true_vector) < len(pred_vector):\n",
    "            continue\n",
    "\n",
    "        start_index, end_index, min_diff = find_closest_subarray(true_vector, pred_vector)\n",
    "        predicted_RUL = [max(len(true_vector) - e_index, 0) for e_index in end_index]\n",
    "        for p_RUL, m_diff in zip(predicted_RUL, min_diff):\n",
    "            storage.append([p_RUL, m_diff])\n",
    "    \n",
    "    storage.sort(key=lambda x: x[1])\n",
    "    storage = torch.Tensor(storage).to(device)\n",
    "    predicted_RUL = (storage[:5, 0]*storage[:5, 1]).sum().item() / storage[:5, 1].sum().item()\n",
    "    results_RUL[machine_id] = predicted_RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../datasets/RUL_FD001.txt', 'r') as f:\n",
    "    true_ruls = [int(row.strip()) for row in f]\n",
    "\n",
    "true_ruls = torch.FloatTensor(true_ruls).to(device)\n",
    "results_RUL_tensor = torch.FloatTensor(tuple(results_RUL.values())).to(device)\n",
    "\n",
    "true_ruls[true_ruls > 125] = 125\n",
    "results_RUL_tensor[results_RUL_tensor > 125] = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_func = RMSELoss()\n",
    "\n",
    "loss = l_func(results_RUL_tensor, true_ruls)\n",
    "print(f'{loss=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_func = RULScore()\n",
    "rul_score = s_func(results_RUL_tensor, true_ruls)\n",
    "print(f'{rul_score=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame((true_ruls.cpu().numpy(), results_RUL_tensor.cpu().numpy()), index=('true', 'predicted')).T.melt(ignore_index=False)\n",
    "\n",
    "plot_path = '../../Plots/experiments/RUL/top-3/'\n",
    "check_path(plot_path)\n",
    "\n",
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "sns.lineplot(data=df,\n",
    "             x=df.index,\n",
    "             y='value',\n",
    "             hue='variable',\n",
    "             ax=ax)\n",
    "\n",
    "ax.set_ylabel('Remaining Useful Life')\n",
    "ax.set_xlabel('Machine id')\n",
    "ax.legend(title=None)\n",
    "ax.set_title(f'RULScore: {rul_score:.3f},   RMSE: {loss:.3f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plot_path, 'smooth.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = get_predictions(train_loader, train_dataset, linear_model)\n",
    "test_predictions = get_predictions(test_loader, test_dataset, linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_RUL = dict()\n",
    "\n",
    "for machine_id in tqdm(test_dataset.machine_ids.unique(), file=sys.stdout):\n",
    "    machine_id = int(machine_id.item())\n",
    "    pred_vector = test_predictions[test_predictions[:,0] == machine_id][:,1].flatten()\n",
    "\n",
    "    storage = list()\n",
    "\n",
    "    for true_machine_id in train_dataset.machine_ids.unique():\n",
    "        true_machine_id = int(true_machine_id.item())\n",
    "        true_vector = train_predictions[train_predictions[:,0] == true_machine_id][:, 1].flatten()\n",
    "\n",
    "        if len(true_vector) < len(pred_vector):\n",
    "            continue\n",
    "        start_index, end_index, min_diff = find_closest_subarray(true_vector, pred_vector)\n",
    "        predicted_RUL = [max(len(true_vector) - e_index, 0) for e_index in end_index]\n",
    "        for p_RUL, m_diff in zip(predicted_RUL, min_diff):\n",
    "            storage.append([p_RUL, m_diff])\n",
    "    \n",
    "    storage.sort(key=lambda x: x[1])\n",
    "    storage = torch.Tensor(storage).to(device)\n",
    "    predicted_RUL = (storage[:5, 0]*storage[:5, 1]).sum().item() / storage[:5, 1].sum().item()\n",
    "    results_RUL[machine_id] = predicted_RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../datasets/RUL_FD001.txt', 'r') as f:\n",
    "    true_ruls = [int(row.strip()) for row in f]\n",
    "\n",
    "true_ruls = torch.FloatTensor(true_ruls).to(device)\n",
    "results_RUL_tensor = torch.FloatTensor(tuple(results_RUL.values())).to(device)\n",
    "true_ruls[true_ruls > 125] = 125\n",
    "results_RUL_tensor[results_RUL_tensor > 125] = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_func = RMSELoss()\n",
    "\n",
    "loss = l_func(results_RUL_tensor, true_ruls)\n",
    "print(f'{loss=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_func = RULScore()\n",
    "rul_score = s_func(results_RUL_tensor, true_ruls)\n",
    "print(f'{rul_score=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame((true_ruls.cpu().numpy(), results_RUL_tensor.cpu().numpy()), index=('true', 'predicted')).T.melt(ignore_index=False)\n",
    "\n",
    "plot_path = '../../Plots/experiments/RUL/top-3/'\n",
    "check_path(plot_path)\n",
    "\n",
    "plt.close()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "sns.lineplot(data=df,\n",
    "             x=df.index,\n",
    "             y='value',\n",
    "             hue='variable',\n",
    "             ax=ax)\n",
    "\n",
    "ax.set_ylabel('Remaining Useful Life')\n",
    "ax.set_xlabel('Machine id')\n",
    "ax.legend(title=None)\n",
    "ax.set_title(f'RULScore: {rul_score:.3f},   RMSE: {loss:.3f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plot_path, 'with_train.png'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
